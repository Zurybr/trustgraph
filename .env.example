# TrustGraph - Environment Configuration
# Copiar a .env y configurar valores reales
# ============================================================================
# SELECCIÓN DE PROVEEDOR LLM
# ============================================================================
# Opciones: openai, anthropic, zai, kimi, minimax, ollama
# - openai: GPT-4, GPT-3.5 (https://api.openai.com)
# - anthropic: Claude (https://api.anthropic.com)
# - zai: GLM-5, GLM-4.6V (https://api.z.ai) - OpenAI compatible
# - kimi: Kimi K2, Kimi Code (https://api.kimi.com) - Anthropic compatible
# - minimax: MiniMax-M2.5 (https://api.minimax.io) - Anthropic compatible
# - ollama: Modelos locales (http://localhost:11434)
LLM_PROVIDER=openai

# ============================================================================
# PROVEEDORES OPENAI-COMPATIBLES
# (Usan formato OpenAI: base_url + api_key)
# ============================================================================

# --- OpenAI Nativo ---
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o

# --- Z.AI (智谱AI/GLM) ---
# Endpoint general: https://api.z.ai/api/paas/v4
# Endpoint Coding: https://api.z.ai/api/coding/paas/v4
ZAI_API_KEY=your-zai-api-key
ZAI_BASE_URL=https://api.z.ai/api/paas/v4
ZAI_MODEL=glm-5

# ============================================================================
# PROVEEDORES ANTHROPIC-COMPATIBLES
# (Usan formato Anthropic: base_url + auth_token)
# ============================================================================

# --- Anthropic Nativo ---
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_BASE_URL=https://api.anthropic.com
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# --- Kimi (Moonshot AI) ---
KIMI_API_KEY=sk-kimi-your-api-key-here
KIMI_BASE_URL=https://api.kimi.com/coding
KIMI_MODEL=kimi-k2

# --- MiniMax ---
# International: https://api.minimax.io/anthropic
# China: https://api.minimaxi.com/anthropic
MINIMAX_API_KEY=your-minimax-api-key
MINIMAX_BASE_URL=https://api.minimax.io/anthropic
MINIMAX_MODEL=MiniMax-M2.5

# ============================================================================
# OLLAMA (LOCAL)
# ============================================================================
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3.1

# ============================================================================
# EMBEDDINGS CONFIGURATION
# ============================================================================
# Opciones: openai, zai, ollama
# Z.ai también ofrece embeddings compatibles con OpenAI
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small

# ============================================================================
# CONFIGURACIÓN AVANZADA (Opcional)
# ============================================================================

# Timeouts y rendimiento
# API_TIMEOUT_MS=300000
# REQUEST_RETRIES=3

# Logging
LOG_LEVEL=INFO

# ============================================================================
# DOCUMENTATION PROJECT SETTINGS
# ============================================================================
CONTEXT_CORE_ID=documentation
CONTEXT_CORE_NAME="Workspace Documentation"
COLLECTION_NAME=docs
