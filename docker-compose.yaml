# TrustGraph - Docker Compose Configuration
# Sistema Operativo de Contexto para Agentes de IA
#
# Uso:
#   docker compose up -d          # Iniciar todos los servicios
#   docker compose down           # Detener servicios
#   docker compose logs -f        # Ver logs
#
# Servicios expuestos:
#   - Workbench UI:    http://localhost:8888
#   - API Gateway:     http://localhost:8080
#   - Grafana:         http://localhost:3000
#   - Prometheus:      http://localhost:9090
#   - Qdrant:          http://localhost:6333
#
# CONFIGURACIÓN DE PROVEEDOR LLM:
# Edita .env y cambia LLM_PROVIDER según necesites:
#   - openai    : GPT-4, GPT-3.5
#   - anthropic : Claude
#   - zai       : GLM-5, GLM-4.6V (OpenAI-compatible)
#   - kimi      : Kimi K2 (Anthropic-compatible)
#   - minimax   : MiniMax-M2.5 (Anthropic-compatible)
#   - ollama    : Modelos locales

services:
  # ============================================================================
  # INFRAESTRUCTURA BASE
  # ============================================================================

  # Apache Pulsar - Event Backbone
  pulsar:
    image: apachepulsar/pulsar:3.2.0
    container_name: tg-pulsar
    command: bin/pulsar standalone
    ports:
      - "6650:6650"   # Pulsar binary protocol
      - "8081:8080"   # Pulsar HTTP API
    volumes:
      - pulsar-data:/pulsar/data
    environment:
      - PULSAR_MEM=-Xms512m -Xmx512m
    healthcheck:
      test: ["CMD", "bin/pulsar-admin", "brokers", "healthcheck"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Apache Cassandra - Graph Database
  cassandra:
    image: cassandra:4.1.4
    container_name: tg-cassandra
    ports:
      - "9042:9042"
    volumes:
      - ./data/cassandra:/var/lib/cassandra
    environment:
      - CASSANDRA_CLUSTER_NAME=TrustGraphCluster
      - CASSANDRA_NUM_TOKENS=256
      - CASSANDRA_RPC_ADDRESS=0.0.0.0
      - CASSANDRA_BROADCAST_RPC_ADDRESS=127.0.0.1
      - HEAP_NEWSIZE=512M
      - MAX_HEAP_SIZE=1G
    healthcheck:
      test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Qdrant - Vector Database
  qdrant:
    image: qdrant/qdrant:v1.9.0
    container_name: tg-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./data/qdrant:/qdrant/storage
    environment:
      - QDRANT__LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/localhost/6333 && echo -e 'GET /healthz HTTP/1.1\r\nHost: localhost\r\nConnection: close\r\n\r\n' >&3 && cat <&3 | grep -q '200 OK'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - trustgraph-network
    restart: unless-stopped

  # ============================================================================
  # SERVICIOS TRUSTGRAPH
  # ============================================================================

  # API Gateway - Entry point for REST API
  api-gateway:
    image: trustgraph/trustgraph-flow:1.8.19
    container_name: tg-api-gateway
    command: api-gateway --pulsar-host pulsar://pulsar:6650 --port 8080
    ports:
      - "8080:8080"
    environment:
      - PULSAR_HOST=pulsar://pulsar:6650
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Provider selection
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      # OpenAI-compatible providers
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - ZAI_BASE_URL=${ZAI_BASE_URL:-https://api.z.ai/api/paas/v4}
      - ZAI_MODEL=${ZAI_MODEL:-glm-5}
      # Anthropic-compatible providers
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-https://api.anthropic.com}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - KIMI_API_KEY=${KIMI_API_KEY:-}
      - KIMI_BASE_URL=${KIMI_BASE_URL:-https://api.kimi.com/coding}
      - KIMI_MODEL=${KIMI_MODEL:-kimi-k2}
      - MINIMAX_API_KEY=${MINIMAX_API_KEY:-}
      - MINIMAX_BASE_URL=${MINIMAX_BASE_URL:-https://api.minimax.io/anthropic}
      - MINIMAX_MODEL=${MINIMAX_MODEL:-MiniMax-M2.5}
      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
    depends_on:
      pulsar:
        condition: service_healthy
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Graph RAG Service
  graph-rag:
    image: trustgraph/trustgraph-flow:1.8.19
    container_name: tg-graph-rag
    command: graph-rag --pulsar-host pulsar://pulsar:6650
    environment:
      - PULSAR_HOST=pulsar://pulsar:6650
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Provider selection
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      # OpenAI-compatible providers
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - ZAI_BASE_URL=${ZAI_BASE_URL:-https://api.z.ai/api/paas/v4}
      - ZAI_MODEL=${ZAI_MODEL:-glm-5}
      # Anthropic-compatible providers
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-https://api.anthropic.com}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - KIMI_API_KEY=${KIMI_API_KEY:-}
      - KIMI_BASE_URL=${KIMI_BASE_URL:-https://api.kimi.com/coding}
      - KIMI_MODEL=${KIMI_MODEL:-kimi-k2}
      - MINIMAX_API_KEY=${MINIMAX_API_KEY:-}
      - MINIMAX_BASE_URL=${MINIMAX_BASE_URL:-https://api.minimax.io/anthropic}
      - MINIMAX_MODEL=${MINIMAX_MODEL:-MiniMax-M2.5}
      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
    depends_on:
      pulsar:
        condition: service_healthy
      cassandra:
        condition: service_healthy
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Document Embeddings
  doc-embeddings:
    image: trustgraph/trustgraph-flow:1.8.19
    container_name: tg-doc-embeddings
    command: document-embeddings --pulsar-host pulsar://pulsar:6650
    environment:
      - PULSAR_HOST=pulsar://pulsar:6650
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Embeddings configuration
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-openai}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      # OpenAI-compatible (used for openai, zai embeddings)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - ZAI_BASE_URL=${ZAI_BASE_URL:-https://api.z.ai/api/paas/v4}
      # Ollama
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
    depends_on:
      pulsar:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    networks:
      - trustgraph-network
    restart: unless-stopped

  # LLM Gateway - Routing entre proveedores (opcional, para configuración avanzada)
  # Este servicio puede usarse para centralizar la lógica de proveedores
  llm-gateway:
    image: trustgraph/trustgraph-flow:1.8.19
    container_name: tg-llm-gateway
    command: llm-gateway --pulsar-host pulsar://pulsar:6650
    environment:
      - PULSAR_HOST=pulsar://pulsar:6650
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      # Provider selection
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      # All provider configs (same as above)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o}
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - ZAI_BASE_URL=${ZAI_BASE_URL:-https://api.z.ai/api/paas/v4}
      - ZAI_MODEL=${ZAI_MODEL:-glm-5}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-https://api.anthropic.com}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - KIMI_API_KEY=${KIMI_API_KEY:-}
      - KIMI_BASE_URL=${KIMI_BASE_URL:-https://api.kimi.com/coding}
      - KIMI_MODEL=${KIMI_MODEL:-kimi-k2}
      - MINIMAX_API_KEY=${MINIMAX_API_KEY:-}
      - MINIMAX_BASE_URL=${MINIMAX_BASE_URL:-https://api.minimax.io/anthropic}
      - MINIMAX_MODEL=${MINIMAX_MODEL:-MiniMax-M2.5}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.1}
    depends_on:
      pulsar:
        condition: service_healthy
    networks:
      - trustgraph-network
    restart: unless-stopped
    profiles: ["advanced"]  # Solo inicia con: docker compose --profile advanced up

  # Workbench UI - Interfaz web oficial
  workbench:
    image: trustgraph/workbench-ui:latest
    container_name: tg-workbench
    ports:
      - "8888:8080"
    environment:
      - TRUSTGRAPH_URL=http://api-gateway:8080
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      - api-gateway
    networks:
      - trustgraph-network
    restart: unless-stopped

  # ============================================================================
  # OBSERVABILIDAD
  # ============================================================================

  # Prometheus - Métricas
  prometheus:
    image: prom/prometheus:v2.51.0
    container_name: tg-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Grafana - Dashboards
  grafana:
    image: grafana/grafana:10.4.0
    container_name: tg-grafana
    ports:
      - "3000:3000"
    volumes:
      - ./data/grafana:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    depends_on:
      - prometheus
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Loki - Logging
  loki:
    image: grafana/loki:2.9.0
    container_name: tg-loki
    ports:
      - "3100:3100"
    volumes:
      - ./config/loki.yml:/etc/loki/local-config.yaml:ro
      - ./data/loki:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - trustgraph-network
    restart: unless-stopped

  # Promtail - Log collector
  promtail:
    image: grafana/promtail:2.9.0
    container_name: tg-promtail
    volumes:
      - ./config/promtail.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - trustgraph-network
    restart: unless-stopped

volumes:
  pulsar-data:
    driver: local

networks:
  trustgraph-network:
    driver: bridge
    name: trustgraph-network
